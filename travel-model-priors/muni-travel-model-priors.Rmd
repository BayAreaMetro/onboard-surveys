---
title: "Muni Travel Model Priors"
author: "David Ory"
output: 
   html_document:
      theme: cosmo
      toc: yes
---

## Administration

#### Purpose
This script consumes boarding and alighting data from SF Muni automated passenger counters, boarding and alighting flows from the SFCTA SF-CHAMP travel model, route segment definitions provided by SF Muni, and a crosswalk connecting the APC and travel model data.  It combines this data to generate an estimate of boarding and alighting flows consistent with both the APC and travel model data for potenital use as prior estimates of flows on SF Muni.  

#### Outputs
1.  A consolidated database of flow estimates

#### _TODO_
0.  Incorporate Drew's consolidated file
1.  Scale rail boardings by some observed number
2.  Build and apply time of day crosswalk
3.  Select one route by one direction and time of day category for demo log-lin application
4.  Generalize application for all routes and time of day categories
5.  Select output format and test
6.  Socialize progress
7.  Build out cross-walk databases (assistance?)
8.  Build out rail cross-walk databases
9.  Generate rail estimates (which are simply the scaled model results)
10.  Separate script: generic chi-squared tester using this as an input file and a standard survey input file

## Procedure

#### Overhead
```{r overhead, results = 'hide'}
library(knitr)
library(reshape2)
suppressMessages(library(dplyr))
library(stringr)
```

```{r config, include=FALSE}
knitr::opts_chunk$set(cache=TRUE)
```

#### Remote I/O Locations
```{r remote-io}
F_APC_COUNTS     = "M:/Data/Transit/Muni APC Through Time/consolidated-database.csv"
F_CHAMP_FLOWS    = "M:/Data/OnBoard/Data and Reports/Muni/travel-model-priors/champ-flows/test-flows.csv"
F_APC_SEGMENTS   = "muni-apc-segments-database.csv"
F_CHAMP_SEGMENTS = "muni-champ-segments-database.csv"

F_OUTPUT = "M:/Data/OnBoard/Data and Reports/Muni/travel-model-priors/test-output-priors.csv"
```

#### Data reads
```{r data-reads}
apc_counts     <- read.table(file = F_APC_COUNTS, header = TRUE, sep = ",", stringsAsFactors = FALSE)
champ_flows    <- read.table(file = F_CHAMP_FLOWS, header = TRUE, sep = ",", stringsAsFactors = FALSE)
apc_segments   <- read.table(file = F_APC_SEGMENTS, header = TRUE, sep = ",", stringsAsFactors = FALSE)
champ_segments <- read.table(file = F_CHAMP_SEGMENTS, header = TRUE, sep = ",", stringsAsFactors = FALSE)
```

#### Prepare CHAMP data
```{r prep-champ}
champ_df <- champ_flows %>%
  select(champ_name, board_stop_sequence = SeqA, alight_stop_sequence = SeqB, time_of_day = TimeOfDay, flow = Trips)

# First join to get APC route name and direction
join_A <- champ_segments %>%
  group_by(champ_name, apc_route, apc_direction) %>%
  summarise(count = n()) %>%
  select(-count)
champ_df <- left_join(champ_df, join_A, by = c("champ_name"))

# Next join the boarding segment
join_B <- champ_segments %>%
  select(champ_name, 
         champ_board_stop_location = stop_location, 
         board_stop_sequence = stop_sequence, 
         board_segment = segment)
champ_df <- left_join(champ_df, join_B, by = c("champ_name", "board_stop_sequence"))

# Next join the alighting segment
join_C <- champ_segments %>%
  select(champ_name, 
         champ_alight_stop_location = stop_location, 
         alight_stop_sequence = stop_sequence, 
         alight_segment = segment)
champ_df <- left_join(champ_df, join_C, by = c("champ_name", "alight_stop_sequence"))

# Summarize
champ_sum <- champ_df %>%
  group_by(champ_name, apc_route, apc_direction, time_of_day, board_segment, alight_segment) %>%
  summarise(flow = sum(flow))

# Q/A
check <- champ_sum %>%
  group_by(apc_route, apc_direction) %>%
  summarise(boardings = sum(flow))

head(check, n = 20)

remove(join_A, join_B, join_C, check, champ_df)

```

#### Extract rail counts from CHAMP data
# TODO 
scale by actual ridership daily estimate
```{r rail-counts-from-champ}
# Build a crosswalk
champ_name   = c("MUNFI", "MUNFO", "MUNJI", "MUNJO", "MUNKI", "MUNKO", "MUNLI", "MUNLO", "MUNMI", "MUNMO", "MUNNI", "MUNNO")
rail_names <- data.frame(champ_name)
rail_names <- rail_names %>%
  mutate(is_rail = TRUE)

# Extract the data
rail_df <- left_join(champ_sum, rail_names, by = c("champ_name"))
rail_df <- na.omit(rail_df)

# Boardings, then alightings
rail_board <- rail_df %>%
  select(apc_route, apc_direction, segment = board_segment, time_of_day, boardings = flow) %>%
  group_by(apc_route, apc_direction, segment, time_of_day) %>%
  summarise(boardings = sum(boardings))

rail_alight <- rail_df %>%
  select(apc_route, apc_direction, segment = alight_segment, time_of_day, alightings = flow) %>%
  group_by(apc_route, apc_direction, segment, time_of_day) %>%
  summarise(alightings = sum(alightings))

# Join
rail_counts <- merge(rail_board, rail_alight, by = c("apc_route", "apc_direction", "time_of_day", "segment"), all = TRUE)

remove(rail_board, rail_alight, rail_names, champ_name, rail_df)

```

#### Prepare APC data 
```{r prep-apc}
# Join with the rail data
apc_df <- rbind(apc_counts, rail_counts)

# Select one tranche of counts and the data I need
apc_df <- apc_df %>%
  filter(start_date == "2015-02-02" | start_date == "2/2/2015") %>%
  filter(week_part == "WEEKDAYS") %>%
  select(route, direction, stop_location, stop_sequence, time_of_day, boardings, alightings)

# Join the segments and filter
apc_df <- left_join(apc_df, apc_segments, by = c("route", "direction", "stop_sequence"))
apc_df <- na.omit(apc_df)

table(apc_df$route)

# Sum by segment
apc_sum <- apc_df %>%
  group_by(route, direction, time_of_day, segment) %>%
  summarise(boardings = sum(boardings), alightings = sum(alightings))

```

# Reference
Apply a log linear model to do IPF efficiently
```{r loglin-reference}
mat <- matrix(c(65,4,22,24,6,81,5,8,0,11,85,19,4,7,3,90),4,4)

rowmarg <- rep(100, nrow(mat))  # the row margin totals that you want

colmarg <- c(90, 120, 80, 110)  # the column margin totals that you want

newmat <- loglin( outer(rowmarg, colmarg) / sum(rowmarg), margin=list(1,2),
start=mat, fit=TRUE, eps=1.e-05, iter=100)$fit

newmat

apply(newmat, 1, sum)

apply(newmat, 2, sum)



```

